{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dive into LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the openAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"./.env\")\n",
    "API_KEY = os.getenv(\"API_OAI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum mechanics is a fundamental theory in physics that describes the behavior of matter and energy at the smallest scales, where particles exhibit wave-particle duality and uncertainty principles, leading to phenomena that defy classical intuition.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = \"Explain Quantum Mechanics in one sentence\"\n",
    "\n",
    "llm = ChatOpenAI(api_key=API_KEY, model=\"gpt-4o-mini\")\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the roles using LangChain\n",
    "from langchain.schema import (\n",
    "\tSystemMessage,\n",
    "\tAIMessage,\n",
    "\tHumanMessage\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik ist die Theorie, die das Verhalten von Materie und Energie auf der kleinsten Skala, der atomaren und subatomaren Ebene, beschreibt und dabei Konzepte wie Superposition und Verschränkung einführt.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "\tSystemMessage(content=\"Your are a physisit and respond only in German\"),\n",
    "\tHumanMessage(content=\"Explain Quantum Mechanics in one sentence\")\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching LLM Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-memory cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name = \"gpt-3.5-turbo-instruct\", api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.4 ms, sys: 18.6 ms, total: 74 ms\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy did the banana go to the doctor?\\nBecause it wasn't peeling well!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "prompt = \"Tell me a joke that a toddler can understand.\"\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 238 μs, sys: 45 μs, total: 283 μs\n",
      "Wall time: 286 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWhy did the banana go to the doctor?\\nBecause it wasn't peeling well!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Title: \"Raven on the Moon\"**\n",
      "\n",
      "**Verse 1**  \n",
      "Under midnight's velvet skies,  \n",
      "A silver glow ignites our eyes,  \n",
      "Where shadows dance and whispers play,  \n",
      "The raven calls, it leads the way.  \n",
      "\n",
      "**Pre-Chorus**  \n",
      "With feathers black as darkest night,  \n",
      "He soars through stars, a ghost in flight,  \n",
      "The Moon is high, a watchful shroud,  \n",
      "Together we'll break free from the crowd.\n",
      "\n",
      "**Chorus**  \n",
      "Raven on the Moon, take me higher,  \n",
      "Through the darkness, set my soul on fire,  \n",
      "In the stillness, we find our truth,  \n",
      "With wings of midnight, we’ll break loose.  \n",
      "\n",
      "**Verse 2**  \n",
      "Echoes of the past, they linger near,  \n",
      "A haunting song that draws us here,  \n",
      "With every beat, my heart aligns,  \n",
      "To the rhythm of ancient times.  \n",
      "\n",
      "**Pre-Chorus**  \n",
      "The Moon it glows, casting spells so bright,  \n",
      "With every flap, we ignite the night,  \n",
      "Lost in dreams, we’ll ride the tides,  \n",
      "A cosmic dance where our fate collides.\n",
      "\n",
      "**Chorus**  \n",
      "Raven on the Moon, take me higher,  \n",
      "Through the darkness, set my soul on fire,  \n",
      "In the stillness, we find our truth,  \n",
      "With wings of midnight, we’ll break loose.  \n",
      "\n",
      "**Bridge**  \n",
      "Soaring past the craters and the dust,  \n",
      "Unraveling the mysteries, in fate we trust,  \n",
      "With every glance, the Universe unfolds,  \n",
      "Together forever, we’re brave and bold.  \n",
      "\n",
      "**Chorus**  \n",
      "Raven on the Moon, take me higher,  \n",
      "Through the darkness, set my soul on fire,  \n",
      "In the stillness, we find our truth,  \n",
      "With wings of midnight, we’ll break loose.  \n",
      "\n",
      "**Outro**  \n",
      "Oh, under the lunar glow, we howl,  \n",
      "The Raven's call, it fuels our growl,  \n",
      "On this journey, we will never wane,  \n",
      "A bond unbroken, in joy and pain.  \n",
      "\n",
      "**(Fade out with electric guitar solo, building into a crescendo before drifting into silence.)**"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key=API_KEY, model=\"gpt-4o-mini\")\n",
    "prompt = \"Write a rock song about the Moon and a Raven.\"\n",
    "for chunk in llm.stream(prompt):\n",
    "\tprint(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le VIH, ou virus de l'immunodéficience humaine, est un rétrovirus qui attaque le système immunitaire, notamment les cellules CD4, cruciales pour la défense de l'organisme contre les infections. Si le VIH n'est pas traité, il peut évoluer vers le sida, une phase où le système immunitaire est gravement compromis. La transmission du VIH se produit principalement par les relations sexuelles non protégées, le partage de seringues et de la mère à l'enfant pendant la grossesse, l'accouchement ou l'allaitement. Grâce aux avancées en matière de traitements antirétroviraux, les personnes vivant avec le VIH peuvent mener une vie saine et réduire considérablement le risque de transmission.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "template = ''' You are an experienced virologist.\n",
    "Write a few senteces about the following virus {virus} in {language}\n",
    "'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt = prompt_template.format(virus=\"hiv\", language=\"french\")\n",
    "\n",
    "llm = ChatOpenAI(api_key=API_KEY, model=\"gpt-4o-mini\")\n",
    "output = llm.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You respond only in the JSON format', additional_kwargs={}, response_metadata={}), HumanMessage(content='Top 10 contries in Europe by population', additional_kwargs={}, response_metadata={})]\n",
      "{\n",
      "    \"1\": {\n",
      "        \"country\": \"Germany\",\n",
      "        \"population\": 83019200\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"country\": \"France\",\n",
      "        \"population\": 67158000\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"country\": \"United Kingdom\",\n",
      "        \"population\": 66040229\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"country\": \"Italy\",\n",
      "        \"population\": 60376370\n",
      "    },\n",
      "    \"5\": {\n",
      "        \"country\": \"Spain\",\n",
      "        \"population\": 46733038\n",
      "    },\n",
      "    \"6\": {\n",
      "        \"country\": \"Ukraine\",\n",
      "        \"population\": 41660983\n",
      "    },\n",
      "    \"7\": {\n",
      "        \"country\": \"Poland\",\n",
      "        \"population\": 38433600\n",
      "    },\n",
      "    \"8\": {\n",
      "        \"country\": \"Romania\",\n",
      "        \"population\": 19405156\n",
      "    },\n",
      "    \"9\": {\n",
      "        \"country\": \"Netherlands\",\n",
      "        \"population\": 17424591\n",
      "    },\n",
      "    \"10\": {\n",
      "        \"country\": \"Belgium\",\n",
      "        \"population\": 11589623\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\tSystemMessage(content=\"You respond only in the JSON format\"),\n",
    "\t\tHumanMessagePromptTemplate.from_template(\"Top {n} contries in {area} by population\")\n",
    "\t]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(n=\"10\", area=\"Europe\")\n",
    "print(messages)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key=API_KEY)\n",
    "output = llm.invoke(messages)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
